{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inizializzazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv(\"data\\compas-analysis\\compas-scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.2\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ricerca di colonne ridondanti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eq_col(data, feat1, feat2):\n",
    "    for x in range(0, 11757):\n",
    "        assert data[feat1].iloc[x] == data[feat2].iloc[x]\n",
    "    print(f\"{feat1} è uguale a {feat2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da questa funzione risultano uguali le colonne:\n",
    "* \"decile_score\" e \"decile_score.1\"\n",
    "* \"compas_screening_date\", \"v_screening_date\" e \"screening_date\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicati(data, feature):\n",
    "    n_arr = data[feature]\n",
    "    n_set = {x for x in n_arr}\n",
    "    return n_set\n",
    "\n",
    "def display(data):\n",
    "    print(\"-----------\")\n",
    "    for item in data.columns:\n",
    "        dup = duplicati(data, item)\n",
    "        if item == \"id\":\n",
    "            tot = len(dup)\n",
    "        if item != \"id\":\n",
    "            res = len(dup)\n",
    "            if tot == res:\n",
    "                print(item, \"CANDIDATE KEY!\")\n",
    "            else:\n",
    "                if res > 20:\n",
    "                    print(item, res)\n",
    "                else:\n",
    "                    print(item, dup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da questa funzione risultano:\n",
    "\n",
    "* In quanto ridondantemente categorici:\n",
    "\n",
    "    * age_cat\n",
    "    * v_score_text\n",
    "    * score_text\n",
    "\n",
    "* In quanto poco informativi:\n",
    "\n",
    "    * num_r_cases\n",
    "    * num_vr_cases\n",
    "    * v_type_of_assessment = {'Risk of Violence'} \n",
    "    * type_of_assessment = {'Risk of Recidivism'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data=data, columns=[\n",
    "    'id',\n",
    "    'name',\n",
    "    'first',\n",
    "    'last',\n",
    "    'sex',\n",
    "    'dob',\n",
    "    'age',\n",
    "    'race',\n",
    "    'juv_fel_count',\n",
    "    'juv_misd_count',\n",
    "    'juv_other_count',\n",
    "    'priors_count',\n",
    "    'days_b_screening_arrest',\n",
    "    'c_jail_in',\n",
    "    'c_jail_out',\n",
    "    'c_case_number',\n",
    "    'c_offense_date',\n",
    "    'c_arrest_date',\n",
    "    'c_days_from_compas',\n",
    "    'c_charge_degree',\n",
    "    'c_charge_desc',\n",
    "    'is_recid',\n",
    "    'r_case_number',\n",
    "    'r_charge_degree',\n",
    "    'r_days_from_arrest',\n",
    "    'r_offense_date',\n",
    "    'r_charge_desc',\n",
    "    'r_jail_in',\n",
    "    'r_jail_out',\n",
    "    'is_violent_recid',\n",
    "    'vr_case_number',\n",
    "    'vr_charge_degree',\n",
    "    'vr_offense_date',\n",
    "    'vr_charge_desc',\n",
    "    'v_decile_score',\n",
    "    'decile_score',\n",
    "    'screening_date'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E' interessante notare che possiamo estrarre la storia criminale dei soggetti registrati nel database, con la seguente funzione:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pd.DataFrame(data=data, columns=[\n",
    "    'id',\n",
    "    'dob',\n",
    "    'c_jail_in',\n",
    "    'c_jail_out',\n",
    "    'c_offense_date',\n",
    "    'r_offense_date',\n",
    "    'r_jail_in',\n",
    "    'r_jail_out',\n",
    "    'vr_offense_date',\n",
    "    'screening_date'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(data)\n",
    "print(data['dob'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La tabella contiene dei valori non conformi, come notiamo applicando la funzione \"display()\" alla nuova tabella \"data\":\n",
    "* La colonna \"is_recid\" ha valori -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.is_recid.isin([0.0, 1.0])]\n",
    "data = data[data.v_decile_score.isin(range(1, 11))]\n",
    "data = data[data.decile_score.isin(range(1, 11))]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Alcune colonne contengono dati categorici."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_encode = ['sex', 'race', 'c_charge_degree', 'r_charge_degree', 'vr_charge_degree']\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')  \n",
    "encoded_data = encoder.fit_transform(data[columns_to_encode])\n",
    "encoded_columns = encoder.get_feature_names_out(columns_to_encode) # Nomi delle nuove colonne\n",
    "encoded_df = pd.DataFrame(encoded_data, columns=encoded_columns)\n",
    "data = data.drop(columns=columns_to_encode)  # Rimuovere le colonne originali\n",
    "data = pd.concat([data, encoded_df], axis=1)  # Aggiungere le nuove colonne codificate\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per la gestione delle date:\n",
    "* Le date di incarcerazione sono convertite nel numero di giorni vissuti da innocente\n",
    "* Le date di scarcerazione sono convertite nel numero di giorni vissuti in carcere\n",
    "\n",
    "Piccola nota metodologica:\n",
    "\n",
    "$ d_2 - d_1 = d_2 + (d_0 - d_0) - d_1 = (d_2 - d_0) - (d_1 - d_0) $\n",
    "\n",
    "Questo espediente richiede, come minimo, che la struttura algebrica di riferimento sia almeno un gruppo (additivo). Le date costituiscono un gruppo (additivo, nonfinito), poiché è banale l'isomorfismo tra questa struttura algebrica e un gruppo costituito dall'insieme dei numeri interi e l'operazione di incremento.\n",
    "\n",
    "Premesso, dunque, che $d_0$ può essere una data qualsiasi, tre scelte:\n",
    "\n",
    "* La scelta convenzionale: $d_0 = 01/01/1970$;\n",
    "* La scelta più logica: $d_0 = min(date \\_ nel \\_ dataset) = 14/10/1919$;\n",
    "* La scelta effettivamente selezionata: $d_0 = 24/6/1936$ (è una data di interesse per lo sviluppatore, ed è anche sufficientemente anteriore da coprire tutte le date nel dataset, tranne 5 date di nascita nella colonna \"dob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            id                    name     first           last         dob  \\\n",
      "0          1.0        miguel hernandez    miguel      hernandez  1947-04-18   \n",
      "2          3.0             kevon dixon     kevon          dixon  1982-01-22   \n",
      "3          4.0                ed philo        ed          philo  1991-05-14   \n",
      "4          5.0             marcu brown     marcu          brown  1993-01-21   \n",
      "5          6.0      bouthy pierrelouis    bouthy    pierrelouis  1973-01-22   \n",
      "...        ...                     ...       ...            ...         ...   \n",
      "11752  11753.0        patrick hamilton   patrick       hamilton  1968-05-02   \n",
      "11753  11754.0       raymond hernandez   raymond      hernandez  1993-06-24   \n",
      "11754  11755.0  dieuseul pierre-gilles  dieuseul  pierre-gilles  1981-01-24   \n",
      "11755  11756.0        scott lomagistro     scott     lomagistro  1986-12-04   \n",
      "11756  11757.0                chin yan      chin            yan  1982-02-19   \n",
      "\n",
      "        age  juv_fel_count  juv_misd_count  juv_other_count  priors_count  \\\n",
      "0      69.0            0.0             0.0              0.0           0.0   \n",
      "2      34.0            0.0             0.0              0.0           0.0   \n",
      "3      24.0            0.0             0.0              1.0           4.0   \n",
      "4      23.0            0.0             1.0              0.0           1.0   \n",
      "5      43.0            0.0             0.0              0.0           2.0   \n",
      "...     ...            ...             ...              ...           ...   \n",
      "11752  47.0            0.0             0.0              0.0           1.0   \n",
      "11753  22.0            0.0             3.0              5.0           3.0   \n",
      "11754  35.0            0.0             0.0              0.0           0.0   \n",
      "11755  29.0            0.0             0.0              0.0           2.0   \n",
      "11756  34.0            0.0             0.0              0.0           0.0   \n",
      "\n",
      "       ...  vr_charge_degree_(F1) vr_charge_degree_(F2) vr_charge_degree_(F3)  \\\n",
      "0      ...                    0.0                   0.0                   0.0   \n",
      "2      ...                    0.0                   0.0                   0.0   \n",
      "3      ...                    0.0                   0.0                   0.0   \n",
      "4      ...                    0.0                   0.0                   0.0   \n",
      "5      ...                    0.0                   0.0                   0.0   \n",
      "...    ...                    ...                   ...                   ...   \n",
      "11752  ...                    NaN                   NaN                   NaN   \n",
      "11753  ...                    NaN                   NaN                   NaN   \n",
      "11754  ...                    NaN                   NaN                   NaN   \n",
      "11755  ...                    NaN                   NaN                   NaN   \n",
      "11756  ...                    NaN                   NaN                   NaN   \n",
      "\n",
      "      vr_charge_degree_(F5) vr_charge_degree_(F6) vr_charge_degree_(F7)  \\\n",
      "0                       0.0                   0.0                   0.0   \n",
      "2                       0.0                   0.0                   0.0   \n",
      "3                       0.0                   0.0                   0.0   \n",
      "4                       0.0                   0.0                   0.0   \n",
      "5                       0.0                   0.0                   0.0   \n",
      "...                     ...                   ...                   ...   \n",
      "11752                   NaN                   NaN                   NaN   \n",
      "11753                   NaN                   NaN                   NaN   \n",
      "11754                   NaN                   NaN                   NaN   \n",
      "11755                   NaN                   NaN                   NaN   \n",
      "11756                   NaN                   NaN                   NaN   \n",
      "\n",
      "       vr_charge_degree_(M1) vr_charge_degree_(M2)  vr_charge_degree_(MO3)  \\\n",
      "0                        0.0                   0.0                     0.0   \n",
      "2                        0.0                   0.0                     0.0   \n",
      "3                        0.0                   0.0                     0.0   \n",
      "4                        0.0                   0.0                     0.0   \n",
      "5                        0.0                   0.0                     0.0   \n",
      "...                      ...                   ...                     ...   \n",
      "11752                    NaN                   NaN                     NaN   \n",
      "11753                    NaN                   NaN                     NaN   \n",
      "11754                    NaN                   NaN                     NaN   \n",
      "11755                    NaN                   NaN                     NaN   \n",
      "11756                    NaN                   NaN                     NaN   \n",
      "\n",
      "      vr_charge_degree_nan  \n",
      "0                      1.0  \n",
      "2                      1.0  \n",
      "3                      1.0  \n",
      "4                      1.0  \n",
      "5                      1.0  \n",
      "...                    ...  \n",
      "11752                  NaN  \n",
      "11753                  NaN  \n",
      "11754                  NaN  \n",
      "11755                  NaN  \n",
      "11756                  NaN  \n",
      "\n",
      "[11027 rows x 56 columns]\n",
      "1947-04-18 <class 'str'>\n",
      "3950 <class 'int'>\n",
      "1947-04-18 <class 'str'>\n",
      "3950 <class 'int'>\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Alessandro\\Desktop\\Tesi\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:2606\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:2630\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 1",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res4\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 33\u001b[0m     test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdob\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mcol_converter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdob\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28mprint\u001b[39m(e)\n",
      "Cell \u001b[1;32mIn[16], line 11\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(data, col)\u001b[0m\n\u001b[0;32m      9\u001b[0m pot_dates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m giorno: (giorno\u001b[38;5;241m-\u001b[39mdate(\u001b[38;5;241m1936\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m24\u001b[39m))\u001b[38;5;241m.\u001b[39mdays\n\u001b[0;32m     10\u001b[0m date_converter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m item: pot_dates(date(\u001b[38;5;241m*\u001b[39m[\u001b[38;5;28mint\u001b[39m(n) \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m item\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m)]))\n\u001b[1;32m---> 11\u001b[0m col_converter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m data, col: [date_converter(\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data[col]))]\n\u001b[0;32m     13\u001b[0m test \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     15\u001b[0m item \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdob\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Alessandro\\Desktop\\Tesi\\venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1183\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1181\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(com\u001b[38;5;241m.\u001b[39mapply_if_callable(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m key)\n\u001b[0;32m   1182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m-> 1183\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtakeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_takeable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple(key)\n\u001b[0;32m   1185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1186\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alessandro\\Desktop\\Tesi\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:4221\u001b[0m, in \u001b[0;36mDataFrame._get_value\u001b[1;34m(self, index, col, takeable)\u001b[0m\n\u001b[0;32m   4215\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_engine\n\u001b[0;32m   4217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, MultiIndex):\n\u001b[0;32m   4218\u001b[0m     \u001b[38;5;66;03m# CategoricalIndex: Trying to use the engine fastpath may give incorrect\u001b[39;00m\n\u001b[0;32m   4219\u001b[0m     \u001b[38;5;66;03m#  results if our categories are integers that dont match our codes\u001b[39;00m\n\u001b[0;32m   4220\u001b[0m     \u001b[38;5;66;03m# IntervalIndex: IntervalTree has no get_loc\u001b[39;00m\n\u001b[1;32m-> 4221\u001b[0m     row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m series\u001b[38;5;241m.\u001b[39m_values[row]\n\u001b[0;32m   4224\u001b[0m \u001b[38;5;66;03m# For MultiIndex going through engine effectively restricts us to\u001b[39;00m\n\u001b[0;32m   4225\u001b[0m \u001b[38;5;66;03m#  same-length tuples; see test_get_set_value_no_partial_indexing\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alessandro\\Desktop\\Tesi\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "import re\n",
    "\n",
    "is_valid_date = lambda value: isinstance(value, str) and bool(re.match(r'^\\d{4}-\\d{2}-\\d{2}$', value))\n",
    "data = data[data['dob'].apply(is_valid_date)]\n",
    "\n",
    "print(data)\n",
    "\n",
    "pot_dates = lambda giorno: (giorno-date(1936,6,24)).days\n",
    "date_converter = lambda item: pot_dates(date(*[int(n) for n in item.split('-')]))\n",
    "col_converter = lambda data, col: [date_converter(data.loc[i, col]) for i in range(len(data[col]))]\n",
    "\n",
    "test = data.copy()\n",
    "\n",
    "item = data['dob'][0]\n",
    "print(item, item.__class__)\n",
    "trans = date_converter(item)\n",
    "print(trans, trans.__class__)\n",
    "\n",
    "item_test = test.loc[0, 'dob']\n",
    "print(item_test, item_test.__class__)\n",
    "trans_test = date_converter(item_test)\n",
    "print(trans_test, trans_test.__class__)\n",
    "\n",
    "def date_converter2(item):\n",
    "    res = item.split('-')\n",
    "    res2 = [int(n) for n in res]\n",
    "    res3 = date(*res2)\n",
    "    res4 = pot_dates(res3)\n",
    "    return res4\n",
    "\n",
    "try:\n",
    "    test['dob'] = col_converter(test, 'dob')\n",
    "except AttributeError as e:\n",
    "    print(e)\n",
    "    print(e.obj)\n",
    "\n",
    "print(date_converter(data['screening_date'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Funzione per calcolare la differenza in giorni da una data di riferimento\n",
    "def calcola_differenza(data, riferimento):\n",
    "    try:\n",
    "        # Converte il valore in una data; se fallisce, restituisce il valore originale\n",
    "        data_converted = pd.to_datetime(data, format='%Y-%m-%d', errors='coerce')\n",
    "        if pd.isnull(data_converted):\n",
    "            return data  # Restituisce il valore originale se non è una data valida\n",
    "        return (data_converted - riferimento).days\n",
    "    except Exception as e:\n",
    "        return data  # Restituisce il valore originale in caso di errore\n",
    "\n",
    "# Data di riferimento\n",
    "data_riferimento = datetime(1936, 6, 24)\n",
    "\n",
    "# Lettura del dataset CSV\n",
    "file_csv = r\"C:\\Users\\gianluca.colasuonno\\compas-scores.csv\"\n",
    "df = pd.read_csv(file_csv)\n",
    "\n",
    "# Identificazione e trasformazione delle colonne con date\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':  # Verifica se la colonna contiene stringhe\n",
    "        # Applica la funzione di calcolo differenza alle colonne candidate\n",
    "        df[col] = df[col].apply(lambda x: calcola_differenza(x, data_riferimento))\n",
    "\n",
    "# Stampa il risultato\n",
    "print(\"\\nDataFrame trasformato:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28175\n",
      "28679\n"
     ]
    }
   ],
   "source": [
    "diff_dates = lambda date2, date1: abs(date2-date1).days\n",
    "pot_dates = lambda giorno: (giorno-date(1936,6,24)).days\n",
    "pot2_dates = lambda date2, date1: pot_dates(date2) - pot_dates(date1)\n",
    "\n",
    "def main():\n",
    "    d1 = date(2000,2,28)\n",
    "    d2 = date(2013,9,13)\n",
    "    result1 = diff_dates(d2, d1)\n",
    "    result2 = pot2_dates(d2, d1)\n",
    "    print('{} days between {} and {}'.format(result1, d1, d2))\n",
    "    print('{} days between {} and {}'.format(result2, d1, d2))\n",
    "    print(\"Happy programmer's day!\")\n",
    "\n",
    "# main()\n",
    "\n",
    "career = ['dob', 'screening_date', 'c_offense_date', 'c_jail_in', 'c_jail_out','r_offense_date', 'r_jail_in', 'r_jail_out', 'vr_offense_date']\n",
    "\n",
    "print(pot_dates(date(2013,8,14)))\n",
    "print(pot_dates(date(2014,12,31)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Alcune colonne contengono dati numerici, ma che devono essere riscalati, pena la confusione del modello sull'importanza di certe features contro l'importanza di altre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, QuantileTransformer\n",
    "\n",
    "# 1 Istanzi oggetto per il Min-Max scaling\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# 2 Applichi lo scaling sui dati numerici del DataFrame\n",
    "\n",
    "df_minmax_scaled = data.copy() # Fai una copia per non sovrascrivere il DataFrame originale\n",
    "\n",
    "# 3 Selezioni colonne numeriche (non includo le colonne codificate One Hot)\n",
    "\n",
    "numerical_columns = df_minmax_scaled.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# 4 Applichi lo scaling\n",
    "\n",
    "df_minmax_scaled[numerical_columns] = scaler.fit_transform(df_minmax_scaled[numerical_columns])\n",
    "\n",
    "print(df_minmax_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import precision_score, recall_score, make_scorer\n",
    "names = ['name', 'first', 'last']\n",
    "career = ['dob', 'screening_date', 'c_offense_date', 'c_jail_in', 'c_jail_out','r_offense_date', 'r_jail_in', 'r_jail_out', 'vr_offense_date']\n",
    "target = ['decile_score']\n",
    "X = df_minmax_scaled.filter(items=target, axis=1).values\n",
    "y = df_minmax_scaled['decile_score'].values\n",
    "\n",
    "f\"Shape of X={X.shape} /n Shape of y={y.shape}\"\n",
    "\n",
    "mod1 = LogisticRegression()\n",
    "mod1.fit(X, y)\n",
    "mod1.predict(X)\n",
    "\n",
    "# Metrica personalizzata\n",
    "def min_rec_prec(y_true, y_pred):\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    return min(recall, precision)\n",
    "\n",
    "def scored_min_rec_prec(est, X, y_true, sample_weight=None):\n",
    "    y_pred = est.predict(X)\n",
    "    return min_rec_prec(y_true, y_pred)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator = LogisticRegression,\n",
    "    # param_grid da inserire: tra quali delle configurazioni che indico devo far ottimizzare il modello, date le metriche?\n",
    "    cv = 4,\n",
    "    scoring = {'precision': make_scorer(precision_score),\n",
    "               'recall': make_scorer(recall_score),\n",
    "               'min_rec_prec': make_scorer(min_rec_prec)},\n",
    "    refit='min_rec_prec', # refit: quale delle metriche deve essere utilizzata dal modello per ottimizzarsi?\n",
    "\n",
    ")\n",
    "grid.fit(X, y)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "results = pd.DataFrame(grid.cv_results_) # la metrica è nelle impostazioni dello stimatore selezionato: di default è l'accuracy score = TP+TN/P+N (\"vero su totale\")\n",
    "for score in ['mean_test_recall', 'mean_test_precision', 'mean_test_min_rec_prec']:\n",
    "    plt.plot([_[1] for _ in results['param_class_weight']], results[score], label=score)\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
